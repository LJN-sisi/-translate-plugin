---
description: 
alwaysApply: true
enabled: true
updatedAt: 2026-02-27T14:57:31.167Z
provider: 
---

智能反馈处理与代码优化系统 - 开发规则文档
1. 项目概述
本系统旨在构建一个自动化的网站后端智能体，能够接收前端用户反馈，经过分析、筛选、方案生成、代码修改、测试验证，最终将改进后的代码提交至GitHub，并附带改进说明。系统必须内嵌熔断机制，以控制LLM调用成本与风险，确保系统在预算和资源限制内稳定运行。

2. 核心目标
自动处理用户反馈，识别可自动改进项。

生成代码修改方案并应用。

运行自动化测试并评估结果。

达到发布标准后自动提交GitHub PR。

通过熔断机制实时控制LLM调用量、任务重试次数、并发数等。
4.2 核心处理引擎（所有服务均需内嵌熔断检查）
4.2.1 反馈分析服务
消费队列消息，调用LLM进行意图识别、可行性评估、优先级打分。

熔断点：每次调用LLM前向熔断管理器请求许可。

输出：

若可自动改进，生成结构化分析结果（问题类型、影响范围、相关代码文件建议）。

否则将反馈标记为“需人工介入”并归档。

4.2.2 改进方案生成服务
接收分析结果，结合代码库上下文（通过检索获取相关代码段），调用LLM生成具体修改指令（JSON格式）。

熔断点：调用LLM前检查。

输出：修改指令，包含文件路径、操作类型（replace/insert/delete）、代码块。

4.2.3 代码修改服务
克隆仓库，基于main创建新分支（分支名格式：feedback-{id}-{timestamp}）。

根据修改指令应用代码变更（可使用ast模块或unidiff库）。

熔断点：任何Git操作（clone/branch/commit）前检查。

输出：本地分支的代码快照。

4.2.4 测试服务
运行自动化测试套件（单元测试、集成测试、UI测试），收集测试报告。

调用LLM评估测试报告，判断问题是否解决及代码质量（可选）。

熔断点：运行测试前、调用LLM评估前均需检查。

质量门禁：

测试通过率 = 100%

核心功能覆盖率 ≥ 80%

LLM质量评分 ≥ 7分（若启用）

若未达标且重试次数<3，返回改进方案生成服务重试；否则转人工。

4.2.5 发布决策服务
测试通过后，调用LLM生成改进说明（基于原始反馈和修改摘要）。

通过GitHub API创建PR，包含：

标题：[Auto] 根据用户反馈优化

正文：改进说明 + 测试结果摘要

熔断点：调用LLM生成说明前、GitHub API调用前检查。

同时更新CHANGELOG或相关文档（如README）。

4.3 熔断管理器（核心组件）
作为单例服务，提供RPC或HTTP接口供其他模块查询。

维护实时用量数据：

当前时间段内已消耗的token总数（按天/小时统计）

当前正在处理的任务数

每个任务已消耗的token（防止单任务过大）

加载配置阈值（从数据库或配置文件）：

MAX_DAILY_TOKENS：每日总token上限

MAX_TASK_TOKENS：单个任务最大token（包括所有重试）

MAX_CONCURRENT_TASKS：最大并发任务数

MAX_RETRIES：同一反馈最大重试次数

决策逻辑：

检查当前用量是否超过阈值，若超过则拒绝请求，并返回熔断原因。

若允许，则预占资源（增加计数），任务完成后释放。

记录所有熔断事件到监控数据库，用于告警和分析。

4.4 监控数据库
表设计：

feedback：存储原始反馈、状态、处理结果

task_logs：记录每个任务的生命周期、各阶段耗时

token_usage：记录每次LLM调用的token数、模型、时间

circuit_breaker_events：记录熔断事件（时间、原因、阈值）

5. 接口定义（内部服务间）
所有服务间通信采用HTTP或消息队列。主要接口如下：

5.1 熔断管理器接口
POST /check
请求体：

json
{
  "service": "feedback_analyzer",
  "action": "llm_call",
  "estimated_tokens": 2000,
  "task_id": "uuid"
}
响应：

json
{
  "allowed": true/false,
  "reason": "string",
  "current_usage": {...}
}
POST /release：任务完成后释放预占资源。

5.2 其他服务接口（示例）
反馈分析服务：POST /analyze 接收反馈内容，返回分析结果。

方案生成服务：POST /generate_solution 接收分析结果，返回修改指令。

代码修改服务：POST /apply_changes 接收修改指令，返回分支名。

测试服务：POST /run_tests 接收分支名，返回测试报告。

发布服务：POST /publish 接收分支名和说明，返回PR URL。

6. 数据流与处理流程
用户提交反馈 → API网关写入队列。

反馈分析服务从队列拉取消息，请求熔断检查→允许→调用LLM分析。

若可自动改进，调用方案生成服务（同样先检查熔断）生成修改指令。

代码修改服务检查熔断后执行代码变更，创建分支。

测试服务检查熔断后运行测试，并可选调用LLM评估。

若测试通过，发布服务检查熔断后创建PR；若不通过，根据重试次数决定重试或转人工。

每一步完成后，将状态更新至数据库，并释放熔断预占资源。

7. 熔断机制实现细节
7.1 计数存储
使用Redis存储实时计数器（如daily_tokens:{YYYY-MM-DD}、concurrent_tasks），支持原子增减。

持久化用量定期写入数据库，用于长期分析。

7.2 熔断触发与恢复
当请求被拒绝时，调用方应捕获异常，将任务状态置为“熔断-转人工”，并发送告警。

熔断管理器可配置半开状态，定期尝试恢复（如每10分钟允许一个测试任务）。

7.3 关键阈值配置
每日token上限：建议初始值100万（根据预算调整）。

单任务token上限：5万（防止模型输出过长）。

并发任务数：根据LLM服务QPS和服务器资源设定，初始10。

重试次数：3次。

7.4 熔断事件记录
每次熔断触发需记录：

时间戳

服务名称

操作类型

当前用量/阈值

触发的规则

8. 测试策略
8.1 单元测试
每个服务独立测试，mock LLM调用和外部依赖。

熔断管理器需测试各种阈值场景。

8.2 集成测试
部署完整环境（含消息队列、数据库、mock LLM），测试端到端流程。

模拟反馈输入，验证分支创建、测试运行、PR创建。

8.3 熔断测试
压力测试：并发请求超过阈值，验证熔断正确触发。

长任务测试：模拟大token消耗，验证单任务熔断。

9. 部署与运维
使用Docker Compose编排所有服务（API网关、各处理服务、熔断管理器、数据库、消息队列）。

配置环境变量管理敏感信息（GitHub token、LLM API key）。

日志统一输出到stdout，由容器管理工具收集。

监控：使用Prometheus + Grafana监控系统指标（请求量、熔断次数、token消耗）。

10. 代码规范与提交要求
遵循PEP 8编码规范。

每个函数/类需有docstring。

关键逻辑需添加注释。

使用pre-commit钩子进行代码格式化（black、isort）。

提交信息格式：[模块] 具体改动（如[feedback] 增加意图识别逻辑）。

11. 注意事项
LLM调用安全：对用户反馈内容进行脱敏处理，避免敏感信息泄露。

代码修改风险：修改前备份文件，支持回滚；仅允许修改特定目录（如前端代码），避免修改核心配置。

重试机制：需设置指数退避，避免短时间内频繁重试。

人工介入接口：提供管理后台查看被熔断或失败的任务，支持手动触发重新处理。